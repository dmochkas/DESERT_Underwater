{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os, json, subprocess, re\n",
    "from typing import List, Dict, Iterator, Pattern, Any\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "cea6f91723bbe9a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def period_lambda(pl: float):\n",
    "    return 86400 / pl\n",
    "\n",
    "msgs_per_day = [3, 10, 50, 100, 400]\n",
    "\n",
    "periods = list(map(period_lambda, msgs_per_day))\n",
    "print(periods)"
   ],
   "id": "b1c02f5d6d75d3cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Populate data",
   "id": "565709b9094c1e23"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "MAIN_SCRIPT = \"./run_main.sh\"\n",
    "CONFIG_FILE = \"config.json\"\n",
    "\n",
    "populate = False\n",
    "\n",
    "def populate_from_config(config_path: str = CONFIG_FILE, runner: str = MAIN_SCRIPT, dry_run: bool = False) -> None:\n",
    "    base_dir = Path.cwd()\n",
    "    cfg_path = base_dir / config_path\n",
    "    if not cfg_path.exists():\n",
    "        raise FileNotFoundError(f\"Config file not found: {cfg_path}\")\n",
    "    try:\n",
    "        cfg = json.loads(cfg_path.read_text(encoding=\"utf-8\"))\n",
    "    except json.JSONDecodeError as e:\n",
    "        raise ValueError(f\"Invalid JSON in {cfg_path}: {e}\") from e\n",
    "\n",
    "    desert_env = cfg.get(\"desert_env\")\n",
    "    rounds = cfg.get(\"rng_rounds\", 1)\n",
    "    start_rng = cfg.get(\"rng_start\", 1)\n",
    "    comb: Dict[str, List] = cfg.get(\"combine\", {})\n",
    "    iterations: List[Dict[str, Any]] = cfg.get(\"iterations\", [])\n",
    "\n",
    "    print(f\"Loaded: rng_rounds={rounds}, rng_start={start_rng}, entries={len(iterations)}\")\n",
    "\n",
    "    cmds: List[str] = []\n",
    "    if desert_env:\n",
    "        env_file = (base_dir / desert_env).resolve()\n",
    "        if not env_file.exists():\n",
    "            raise FileNotFoundError(f\"desert_env file not found: {env_file}\")\n",
    "        # Source environment first\n",
    "        cmds.append(f\"source '{env_file}'\")\n",
    "\n",
    "    if \"nn\" not in comb:\n",
    "        comb[\"nn\"] = [0]\n",
    "\n",
    "    if \"period\" not in comb:\n",
    "        comb[\"period\"] = [0]\n",
    "\n",
    "    if \"sink_mode\" not in comb:\n",
    "        comb[\"sink_mode\"] = [0]\n",
    "\n",
    "    for nn_param in comb[\"nn\"]:\n",
    "        for period_param in comb[\"period\"]:\n",
    "            for sink_mode_param in comb[\"sink_mode\"]:\n",
    "                entry = {\n",
    "                    \"nn\": nn_param,\n",
    "                    \"period\": period_param,\n",
    "                    \"sink_mode\": sink_mode_param\n",
    "                }\n",
    "                iterations.append(entry)\n",
    "\n",
    "\n",
    "    for i, it in enumerate(iterations):\n",
    "        if not isinstance(it, dict):\n",
    "            raise ValueError(f\"iterations[{i}] must be an object, got {type(it).__name__}\")\n",
    "        nn = it.get(\"nn\")\n",
    "        period = it.get(\"period\")\n",
    "        sink_mode = it.get(\"sink_mode\")\n",
    "        cmds.append(f\"{runner} {nn} {period} {sink_mode} {rounds} {start_rng}\")\n",
    "\n",
    "    sep = \" && \"\n",
    "    full_cmd = sep.join(cmds)\n",
    "\n",
    "    if dry_run:\n",
    "        print(\"DRY_RUN chained command:\\n\", full_cmd)\n",
    "        return\n",
    "\n",
    "    print(\"Executing bash command...\")\n",
    "    print(full_cmd)\n",
    "    completed = subprocess.run([\"bash\", \"-c\", full_cmd], cwd=base_dir)\n",
    "    if completed.returncode != 0:\n",
    "        raise RuntimeError(f\"Chained command failed with exit code {completed.returncode}\")\n",
    "    print(\"Success!\")\n",
    "\n",
    "if populate:\n",
    "    populate_from_config()"
   ],
   "id": "699662110f4c1071",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Reading trace data, parsing functions",
   "id": "e722191baa198e92"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sink_id_dict = {\n",
    "    \"0\": 254,\n",
    "    \"1\": 253,\n",
    "    \"2\": 252\n",
    "}\n",
    "\n",
    "def parse_file_records(regex: Pattern, path: str) -> Iterator[Dict]:\n",
    "    \"\"\"Yield one dict per matching log line from `path`.\"\"\"\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            m = regex.match(line)\n",
    "            if not m:\n",
    "                continue\n",
    "\n",
    "            sink_id = sink_id_dict[m.group(\"sink_id\")] if m.group(\"sink_id\") in sink_id_dict else m.group(\"sink_id\")\n",
    "            yield {\n",
    "                \"time\": float(m.group(\"time\")),\n",
    "                \"sink_id\": int(sink_id),\n",
    "                \"packet_id\": int(m.group(\"packet_id\")),\n",
    "                \"src_ip\": int(m.group(\"src_ip\")),\n",
    "            }"
   ],
   "id": "e644b73e7be9a37d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def pdr_per_iteration(sink_log_path: str, node_log_path: str) -> float:\n",
    "    _pattern = re.compile(r\"\\[(?P<time>\\d+(?:\\.\\d+)?)\\]::DBG::UWUDP\\((?P<sink_id>\\d+)\\)::recv\\(Packet \\*, int\\)::new packet with id (?P<packet_id>\\d+) from ip (?P<src_ip>\\d+) : \\d+\")\n",
    "\n",
    "    udp_df = df.from_records(parse_file_records(_pattern, sink_log_path))\n",
    "    result_df = pd.read_csv(node_log_path, skiprows=17, header=0)\n",
    "    result_df = result_df.replace(\"_\", np.nan).infer_objects(copy=False)\n",
    "    if verbose:\n",
    "        # print(\"Parsed rows:\", len(udp_df))\n",
    "        print(udp_df.head())\n",
    "        print(result_df.head())\n",
    "\n",
    "    summary = df()\n",
    "    if not udp_df.empty:\n",
    "        summary = udp_df.groupby(\"packet_id\") \\\n",
    "            .agg(first_time=(\"time\", \"min\"), last_time=(\"time\", \"max\"), duplicates=(\"packet_id\", \"count\"), sinks=(\"sink_id\", lambda s: sorted(set(s)))) \\\n",
    "            .reset_index()\n",
    "\n",
    "        if verbose:\n",
    "            print(summary.head())\n",
    "    else:\n",
    "        print(f\"Warning: No matching UDP recv lines found in {sink_log_path}.\")\n",
    "\n",
    "\n",
    "    total_recv = len(summary)\n",
    "    total_sent = result_df[\"n_pkts\"].sum()\n",
    "    total_pdr = (total_recv / total_sent * 100) if total_sent > 0 else 100.0\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Total received packets:\", total_recv)\n",
    "        print(\"Total transmitted packets: \", total_sent)\n",
    "        print(f\"Total PDR: {total_pdr:.2f}\")\n",
    "    return total_pdr"
   ],
   "id": "b11ad298e7ee5bbd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Preparing data",
   "id": "b2e991397fcac20b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "DATA_PATH = \"data/\"\n",
    "EXPERIMENT_ITER = 20\n",
    "\n",
    "verbose = False\n",
    "rows = []\n",
    "for experiment_dir in os.listdir(DATA_PATH):\n",
    "    subdir_path = os.path.join(DATA_PATH, experiment_dir)\n",
    "    if os.path.isdir(subdir_path):\n",
    "        parts = experiment_dir.split('_')\n",
    "\n",
    "        if verbose:\n",
    "            print(parts)\n",
    "        for i in range(1, EXPERIMENT_ITER + 1):\n",
    "            sink_path = os.path.join(subdir_path, f\"{experiment_dir}_{i}_sink.out\")\n",
    "            node_path = os.path.join(subdir_path, f\"{experiment_dir}_{i}_node.out\")\n",
    "            pdr = pdr_per_iteration(sink_path, node_path)\n",
    "            if verbose:\n",
    "                print(i, pdr)\n",
    "            rows.append({\n",
    "                \"nn\": int(parts[0]),\n",
    "                \"period\": float(parts[1]),\n",
    "                \"sink_mode\": int(parts[2]),\n",
    "                \"rng\": int(i),\n",
    "                \"total_pdr\": float(pdr)\n",
    "            })"
   ],
   "id": "4da402e079ff2f78",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Extracting results",
   "id": "9e234696f9bfc21c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results_df = df(rows)\n",
    "\n",
    "results_df = results_df.groupby([\"nn\", \"period\", \"sink_mode\"]) \\\n",
    "    .agg(avg_pdr=(\"total_pdr\", \"mean\")) \\\n",
    "    .reset_index()\n",
    "\n",
    "results_df[\"lambda\"] = results_df[\"period\"].apply(period_lambda)\n",
    "print(results_df.head(100))"
   ],
   "id": "9a57a38a07a5f33a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# pivot so each sink_mode is a column\n",
    "pivot = results_df.pivot_table(\n",
    "    index=[\"nn\", \"lambda\"],\n",
    "    columns=\"sink_mode\",\n",
    "    values=\"avg_pdr\",\n",
    "    aggfunc=\"mean\"\n",
    ").reset_index()\n",
    "\n",
    "pdr_1 = pivot.get(1)\n",
    "pdr_3 = pivot.get(3)\n",
    "\n",
    "pivot[\"pdr_gain_abs\"] = (pdr_3 - pdr_1).abs()\n",
    "pivot[\"pdr_gain_percent\"] = (pdr_3 - pdr_1) / pdr_1 * 100\n",
    "\n",
    "print(pivot.head(100))"
   ],
   "id": "e1dcf24bf1589542",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Plotting",
   "id": "1af2a09be6e0fd59"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results_sink_1_df = results_df[results_df[\"sink_mode\"] == 1]\n",
    "print(results_sink_1_df.head())\n",
    "results_sink_3_df = results_df[results_df[\"sink_mode\"] == 3]\n",
    "print(results_sink_3_df.head())\n",
    "\n",
    "nn_colors = {\n",
    "    1:      \"tab:blue\",\n",
    "    10:     \"tab:orange\",\n",
    "    20:     \"tab:green\",\n",
    "    50:     \"tab:red\",\n",
    "    100:     \"tab:purple\"\n",
    "}\n",
    "\n",
    "plot_data = [\n",
    "    {\n",
    "        \"title\": \"PDR vs PPD with one sink\",\n",
    "        \"linestyle\": \"-\",\n",
    "        \"sink\": 1,\n",
    "        \"df\": results_sink_1_df\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"PDR vs PPD with three sinks\",\n",
    "        \"linestyle\": \"--\",\n",
    "        \"sink\": 3,\n",
    "        \"df\": results_sink_3_df\n",
    "    }\n",
    "]\n",
    "\n",
    "for plot in plot_data:\n",
    "    for nn in plot[\"df\"][\"nn\"].unique():\n",
    "        curr = plot[\"df\"][plot[\"df\"][\"nn\"] == nn]\n",
    "        plt.plot(curr[\"lambda\"], curr[\"avg_pdr\"], color=nn_colors[nn], linestyle=plot[\"linestyle\"], label=f\"nn={nn},s={plot['sink']}\")\n",
    "\n",
    "plt.ylim(0.0, 110.0)\n",
    "plt.yticks(range(0, 101, 10))\n",
    "plt.xlabel(\"Procedures per day\")\n",
    "plt.ylabel(\"Packet delivery rate\")\n",
    "plt.legend()\n",
    "plt.title(\"Title\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "for nn in pivot[\"nn\"].unique():\n",
    "    curr = pivot[pivot[\"nn\"] == nn]\n",
    "    plt.plot(curr[\"lambda\"], curr[\"pdr_gain_percent\"], label=f\"nn={nn}\")\n",
    "\n",
    "plt.ylim(0.0, 110.0)\n",
    "plt.yticks(range(0, 101, 10))\n",
    "plt.xlabel(\"Procedures per day\")\n",
    "plt.ylabel(\"PDR gain, %\")\n",
    "plt.legend()\n",
    "plt.title(\"PDR gain from redundancy\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "dd50d5762b201050",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
